[package]
name = "braincells"
version = "0.1.0"
description = "Braincells - Intelligent Spreadsheet Automation"
authors = ["Dylan Goldblatt <dylan.goldblatt@kennesaw.edu>"]
license = "Apache-2.0"
repository = "https://github.com/kennesaw-state-university/braincells"
edition = "2021"
rust-version = "1.77.2"

[lib]
name = "braincells_lib"
crate-type = ["staticlib", "cdylib", "rlib"]

[build-dependencies]
tauri-build = { version = "2", features = [] }

[dependencies]
# Tauri core
tauri = { version = "2", features = [] }
tauri-plugin-log = "2"
tauri-plugin-shell = "2"
tauri-plugin-fs = "2"
tauri-plugin-dialog = "2"
tauri-plugin-http = "2"
tauri-plugin-updater = "2"

# Async runtime
tokio = { version = "1", features = ["full"] }
futures = "0.3"
async-trait = "0.1"

# Serialization
serde = { version = "1", features = ["derive"] }
serde_json = "1"

# HTTP client for cloud APIs
reqwest = { version = "0.12", features = ["json", "stream"] }

# HuggingFace Hub for model downloads
hf-hub = "0.4"

# Database
rusqlite = { version = "0.32", features = ["bundled"] }

# Error handling
thiserror = "1"
anyhow = "1"

# Logging
log = "0.4"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# Utilities
uuid = { version = "1", features = ["v4", "serde"] }
chrono = { version = "0.4", features = ["serde"] }
dirs = "5"
once_cell = "1"

# LLM inference - llama.cpp bindings
llama-cpp-2 = "0.1"

[target.'cfg(target_os = "macos")'.dependencies]
# Metal support is automatic in llama_cpp on macOS

[target.'cfg(target_os = "windows")'.dependencies]
# CUDA support requires CUDA toolkit installed

[target.'cfg(target_os = "linux")'.dependencies]
# CUDA/ROCm support depends on system configuration

[features]
default = []
cuda = []
metal = []

[profile.release]
lto = true
codegen-units = 1
panic = "abort"
strip = true
